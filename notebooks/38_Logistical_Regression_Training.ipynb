{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 21:38:26.456441: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-29 21:38:27.070420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump\n",
    "from src.general.functions_report import report_training_logistical_regression\n",
    "from src.general.functions_time import tic, toc, get_timestamp\n",
    "from src.data.functions_training_data import load_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tensorflow to GPU-only (data is stored as tensors even when tf is not used)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory:  /home/jupyter-sfaatz\n"
     ]
    }
   ],
   "source": [
    "# Change working directory\n",
    "# working_directory = 'c:/Users/Steph/OneDrive - Universit√§t Bayreuth/Masterarbeit/03_Programmierung/remaining_trace_prediction_master_thesis_stephan_faatz'\n",
    "working_directory = '/home/jupyter-sfaatz/'\n",
    "os.chdir(working_directory)\n",
    "print(\"Working directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 21:38:31.947386: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-12-29 21:38:31.947427: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: jupyter-ext-wi\n",
      "2023-12-29 21:38:31.947432: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: jupyter-ext-wi\n",
      "2023-12-29 21:38:31.947555: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.54.3\n",
      "2023-12-29 21:38:31.947571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.54.3\n",
      "2023-12-29 21:38:31.947575: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.54.3\n"
     ]
    }
   ],
   "source": [
    "# Set path variables\n",
    "path_raw = 'data/raw/'\n",
    "path_interim = 'data/interim/'\n",
    "path_benchmark = 'data/benchmark/'\n",
    "path_data = 'data/processed/'\n",
    "path_control = 'data/control/'\n",
    "path_predictions = 'data/predictions/'\n",
    "path_models = 'models/'\n",
    "path_reports = 'reports/'\n",
    "\n",
    "# Initalize variables\n",
    "filename_variables = 'variables_helpdesk_true.pkl'\n",
    "\n",
    "with open(path_control + filename_variables, 'rb') as file:\n",
    "    variables = pickle.load(file)\n",
    "\n",
    "# Get timestamp\n",
    "variables['logreg_timestamp_training_start'] = get_timestamp()\n",
    "\n",
    "# Set model name\n",
    "variables['regression_model'] = \"logreg_\"+ filename_variables[10:][:-4] +\".joblib\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x_train_tensor shape:  (26332, 12)\n",
      "y_train_tensor shape:  (26332, 1)\n",
      "x_val_tensor shape:    (5643, 12)\n",
      "y_val_tensor shape:    (5643, 1)\n",
      "x_test_tensor shape:   (5643, 12)\n",
      "y_test_tensor shape:  (5643, 12)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load benchmark data\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = load_processed_data(path_benchmark + variables['filename_benchmark_dataset'], tensor = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter\n",
    "variables['logreg_max_iter'] = 1000\n",
    "variables['logreg_n_jobs'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          416     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.12598D+04    |proj g|=  5.23762D+04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  4.15856D+04    |proj g|=  2.17578D+03\n",
      "\n",
      "At iterate  100    f=  3.94304D+04    |proj g|=  2.38739D+03\n",
      "\n",
      "At iterate  150    f=  3.84361D+04    |proj g|=  1.55533D+03\n",
      "\n",
      "At iterate  200    f=  3.79076D+04    |proj g|=  4.71993D+02\n",
      "\n",
      "At iterate  250    f=  3.76291D+04    |proj g|=  1.10622D+03\n",
      "\n",
      "At iterate  300    f=  3.73792D+04    |proj g|=  3.96479D+02\n",
      "\n",
      "At iterate  350    f=  3.72449D+04    |proj g|=  1.00346D+03\n",
      "\n",
      "At iterate  400    f=  3.71561D+04    |proj g|=  2.23781D+02\n",
      "\n",
      "At iterate  450    f=  3.70883D+04    |proj g|=  3.51921D+02\n",
      "\n",
      "At iterate  500    f=  3.70310D+04    |proj g|=  1.44973D+02\n",
      "\n",
      "At iterate  550    f=  3.69866D+04    |proj g|=  6.32614D+02\n",
      "\n",
      "At iterate  600    f=  3.69474D+04    |proj g|=  1.82144D+02\n",
      "\n",
      "At iterate  650    f=  3.69220D+04    |proj g|=  2.64570D+02\n",
      "\n",
      "At iterate  700    f=  3.69025D+04    |proj g|=  2.59698D+02\n",
      "\n",
      "At iterate  750    f=  3.68798D+04    |proj g|=  3.63007D+02\n",
      "\n",
      "At iterate  800    f=  3.68570D+04    |proj g|=  2.14442D+02\n",
      "\n",
      "At iterate  850    f=  3.68329D+04    |proj g|=  9.28926D+01\n",
      "\n",
      "At iterate  900    f=  3.68174D+04    |proj g|=  4.41672D+02\n",
      "\n",
      "At iterate  950    f=  3.68056D+04    |proj g|=  1.42581D+02\n",
      "\n",
      "At iterate 1000    f=  3.67950D+04    |proj g|=  2.09959D+02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  416   1000   1063      1     0     0   2.100D+02   3.679D+04\n",
      "  F =   36794.993687379072     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "\n",
      "Elapsed time: 14.357699 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-sfaatz/env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Initalize model\n",
    "logreg = LogisticRegression(max_iter = variables['logreg_max_iter'], random_state = 29061998, verbose = 1, n_jobs = variables['logreg_n_jobs'],multi_class='multinomial', solver='lbfgs')\n",
    "tic()\n",
    "# Train model\n",
    "logreg.fit(x_train, y_train.flatten()) \n",
    "variables['logreg_elapsed_time'] = toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/logistic_regression/logreg_helpdesk_true.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "dump(logreg, path_models + 'logistic_regression/' + variables['regression_model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.5842636895268474\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "y_val_pred = logreg.predict(x_val)\n",
    "variables['logreg_acc'] = accuracy_score(y_val.flatten(), y_val_pred)\n",
    "print('acc: ',variables['logreg_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "\n",
      "\n",
      "Dataset:                 helpdesk.csv\n",
      "Filename interim data:   interim_data_helpdesk_true.npz\n",
      "Filename variables:      variables_helpdesk_true.pkl\n",
      "\n",
      "\n",
      "vocab (first 6):         ['<pad>' '<unk>' '<start>' '<end>' 'Assign-seriousness'\n",
      " 'Take-in-charge-ticket']\n",
      "vocab_size:              36\n",
      "max_length_trace:        6\n",
      "num_traces:              4255\n",
      "num_ex_activities:       18809\n",
      "num_features:            2\n",
      "features:                ['concept:name', 'org:resource']\n",
      "interleave:              True\n",
      "\n",
      "\n",
      "Samples in training:     (26332, 14)\n",
      "Samples in validation:   (5643, 14)\n",
      "Samples in test:         (5643, 14)\n",
      "\n",
      "\n",
      "Training Logistical Regression:\n",
      "Elapsed time:            14.357698917388916\n",
      "Regression model:        logreg_helpdesk_true.joblib\n",
      "\n",
      "\n",
      "Parameters Logistical Regression:\n",
      "logreg_max_iter:         1000\n",
      "logreg_n_jobs:           -1\n",
      "\n",
      "\n",
      "Training-Evaluation:\n",
      "logreg_acc:              0.5842636895268474\n",
      "\n",
      "Report has been written to 'reports/training/competing_artifacts/logistical_regression/2023-12-29_21-38-31_report_training_logreg_helpdesk_true.txt'\n"
     ]
    }
   ],
   "source": [
    "# Generate report\n",
    "report_training_logistical_regression(filename_variables, variables, variables['logreg_timestamp_training_start'], path_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables saved to  data/control/variables_helpdesk_true.pkl\n"
     ]
    }
   ],
   "source": [
    "# Store variables in pickle file\n",
    "with open(path_control + filename_variables, 'wb') as file:\n",
    "    pickle.dump(variables, file)\n",
    "print(\"Variables saved to \", path_control + filename_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
