{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 21:45:33.574846: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-29 21:45:34.098764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from joblib import load\n",
    "from src.general.functions_time import tic, toc, get_timestamp\n",
    "from src.data.functions_training_data import load_processed_data\n",
    "from src.evaluation.functions_prediction import get_multi_dim_prediction\n",
    "from src.general.functions_report import report_prediction_logistical_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tensorflow to GPU-only (data is stored as tensors even when tf is not used)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory:  /home/jupyter-sfaatz\n"
     ]
    }
   ],
   "source": [
    "# Change working directory\n",
    "# working_directory = 'c:/Users/Steph/OneDrive - Universität Bayreuth/Masterarbeit/03_Programmierung/remaining_trace_prediction_master_thesis_stephan_faatz'\n",
    "working_directory = '/home/jupyter-sfaatz/'\n",
    "os.chdir(working_directory)\n",
    "print(\"Working directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path variables\n",
    "path_raw = 'data/raw/'\n",
    "path_interim = 'data/interim/'\n",
    "path_benchmark = 'data/benchmark/'\n",
    "path_data = 'data/processed/'\n",
    "path_control = 'data/control/'\n",
    "path_predictions = 'data/predictions/'\n",
    "path_models = 'models/'\n",
    "path_reports = 'reports/'\n",
    "\n",
    "# Initalize variables\n",
    "filename_variables = 'variables_helpdesk_true.pkl'\n",
    "\n",
    "with open(path_control + filename_variables, 'rb') as file:\n",
    "    variables = pickle.load(file)\n",
    "\n",
    "# timestamp\n",
    "variables['logreg_timestamp_prediction_start'] = get_timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x_train_tensor shape:  (26332, 12)\n",
      "y_train_tensor shape:  (26332, 1)\n",
      "x_val_tensor shape:    (5643, 12)\n",
      "y_val_tensor shape:    (5643, 1)\n",
      "x_test_tensor shape:   (5643, 12)\n",
      "y_test_tensor shape:  (5643, 12)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load benchmark data\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = load_processed_data(path_benchmark + variables['filename_benchmark_dataset'], tensor = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = load(path_models +'logistic_regression/'+ variables['regression_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 12/12 [00:00<00:00, 64.97it/s]\n",
      "Cleaning predictions: 100%|██████████| 5643/5643 [00:00<00:00, 1388179.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time: 0.194795 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get multidimensional predictions\n",
    "tic()\n",
    "y_pred = get_multi_dim_prediction(logreg, x_test, variables['mapping'])\n",
    "variables['elapsed_time_predictions_logreg'] = toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to  data/predictions/predictions_helpdesk_true.npz\n"
     ]
    }
   ],
   "source": [
    "# Save predictions\n",
    "data_predictions = np.load(path_predictions + variables['filename_predictions'])\n",
    "data_predictions_copy = dict(data_predictions)\n",
    "data_predictions_copy['y_pred_rg'] = y_pred\n",
    "data_predictions_copy['y_test_benchmark'] = y_test\n",
    "np.savez(path_predictions + variables['filename_predictions'], **data_predictions_copy)\n",
    "print(\"Predictions saved to \", path_predictions + variables['filename_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "\n",
      "\n",
      "Dataset:                 helpdesk.csv\n",
      "Filename interim data:   interim_data_helpdesk_true.npz\n",
      "Filename processed data: preprocessed_data_helpdesk_true.npz\n",
      "Filename variables:      variables_helpdesk_true.pkl\n",
      "\n",
      "\n",
      "vocab (first 6):         ['<pad>' '<unk>' '<start>' '<end>' 'Assign-seriousness'\n",
      " 'Take-in-charge-ticket']\n",
      "vocab_size:              36\n",
      "max_length_trace:        6\n",
      "num_traces:              4255\n",
      "num_ex_activities:       18809\n",
      "num_features:            2\n",
      "features:                ['concept:name', 'org:resource']\n",
      "interleave:              True\n",
      "\n",
      "\n",
      "Samples in training:     (26332, 14)\n",
      "Samples in validation:   (5643, 14)\n",
      "Samples in test:         (5643, 14)\n",
      "\n",
      "\n",
      "Prediction Logistical Regression:\n",
      "\n",
      "Elapsed time:            0.1947951316833496\n",
      "Regression model:        logreg_helpdesk_true.joblib\n",
      "\n",
      "\n",
      "Parameters Logistical Regression:\n",
      "\n",
      "logreg_max_iter:         1000\n",
      "logreg_n_jobs:           -1\n",
      "\n",
      "Report has been written to 'reports/prediction/competing_artifacts/logistical_regression/2023-12-29_21-47-18_report_prediction_logreg_helpdesk_true.txt'\n"
     ]
    }
   ],
   "source": [
    "# Generate report\n",
    "report_prediction_logistical_regression(filename_variables, variables, variables['logreg_timestamp_prediction_start'], path_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables saved to  data/control/variables_helpdesk_true.pkl\n"
     ]
    }
   ],
   "source": [
    "# Store variables in pickle file\n",
    "with open(path_control + filename_variables, 'wb') as file:\n",
    "    pickle.dump(variables, file)\n",
    "print(\"Variables saved to \", path_control + filename_variables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
